{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 找不到指定的模块。 Error loading \"D:\\miniconda3\\envs\\studyDeeplearningProject\\lib\\site-packages\\torch\\lib\\caffe2_nvrtc.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#使用pytorch框架简洁实现softmax回归\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01md2l\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m torch \u001B[38;5;28;01mas\u001B[39;00m d2l\n",
      "File \u001B[1;32mD:\\miniconda3\\envs\\studyDeeplearningProject\\lib\\site-packages\\torch\\__init__.py:133\u001B[0m\n\u001B[0;32m    131\u001B[0m                 err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(ctypes\u001B[38;5;241m.\u001B[39mget_last_error())\n\u001B[0;32m    132\u001B[0m                 err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 133\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    135\u001B[0m     kernel32\u001B[38;5;241m.\u001B[39mSetErrorMode(prev_error_mode)\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_preload_cuda_deps\u001B[39m(lib_folder, lib_name):\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 126] 找不到指定的模块。 Error loading \"D:\\miniconda3\\envs\\studyDeeplearningProject\\lib\\site-packages\\torch\\lib\\caffe2_nvrtc.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "#使用pytorch框架简洁实现softmax回归\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "#利用d2l中的包传入batch_size导入训练和测试数据\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#初始化模型\n",
    "#pytorch不会隐式地调整输入的形状，因此，我们在线性层前定义了展平层（flatten)，来调整网络输入的形状\n",
    "net = nn.Sequential(nn.Flatten(),nn.Linear(784,10))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "\n",
    "net.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#计算交叉熵损失\n",
    "loss = nn.CrossEntropyLoss(reduction='none')#reduction='none'表示不对loss进行求平均和求和操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#优化算法\n",
    "trainer = torch.optim.SGD(net.parameters(),lr=0.1)#设置学习率为0.1\n",
    "#trainer是由PyTorch内置的优化器类torch.optim.SGD创建的对象，用于更新神经网络的参数。具体地，通过定义一个trainer对象，你可以使用反向传播算法计算网络的梯度，并根据学习率和梯度对网络的参数进行梯度下降更新"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#接下来我们调用 3.6节中 定义的训练函数来训练模型\n",
    "num_epochs = 10\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}